\chapter{Media Brand Effects}

\section{Motivations}  
Following the limitations and patterns from our first study, we designed a follow-up study to verify interactions between news source and reading level.

This study focused on two main hypotheses:

\begin{itemize}
  \item H1
  \item H2
\end{itemize}


\section{Experimental Design}

For the second study, our experiment was revised to have a 4 x 2 mixed-factorial design.
In this study, reading level of articles and candidates featured in the articles were treated as within-subject variables, and the source of the story between-subjects.

\begin{center}
\begin{table}
\begin{tabular}{ | m{10em} | m{7em}| m{7em} | m{7em} | m{7em} | } 
 \hline
  & \textbf{Source: None} & \textbf{Source: AP} & \textbf{Source: Fox} & \textbf{Source: CNN} \\
 \hline
 \textbf{High Reading Level} & Clinton, Cruz, Sanders, Trump & Clinton, Cruz, Sanders, Trump & Clinton, Cruz, Sanders, Trump & Clinton, Cruz, Sanders, Trump  \\ 
 \textbf{Low Reading Level} & Clinton, Cruz, Sanders, Trump & Clinton, Cruz, Sanders, Trump & Clinton, Cruz, Sanders, Trump & Clinton, Cruz, Sanders, Trump \\ 
 \hline
\end{tabular}
\caption{Main Study Design}
\label{study2}
\end{table}
\end{center}
%\newpage

% \begin{itemize}
%   \item Source (4 levels: None, AP, CNN, Fox)
%   \item Candidate (4 levels: Clinton, Cruz, Sanders, Trump)
%   \item Reading Level (2 levels: High, Low)
% \end{itemize}

This time, we reduced the number of stories to N=8, and also changed reading level from a 3-level to 2-level variable (low, high) for clarity.

Most significantly, since we observed some significant effect from disclosing source to the reader in Study 1, we added a manipulation in this experiment to further study the effect of revealing the source:

Following Baum's research in showing the effects of media brands and reader bias by manipulating reported brands, all eight stories in Study 2 were in fact written by the Associated Press, however, we manipulated the source shown to the reader \cite{baum2008eye}. In group A, readers were shown the headline and text of the story with no other context. In group B, readers were additionally shown that the story was from the Associated Press (true label). In groups C and D, readers were shown that the story was from CNN and Fox News, respectively.

This setup was created to eliminate some of the confounding effects from using stories from different sources (writing style, focus of content, slant, etc.), while directly observing the effect of revealing a specific source to the reader. The Associated Press was chosen as the source of the stories as it is the highest circulation newswire service in the United States, and has 14,000 members that use its content \cite{apFAQ}. Notably, both CNN and Fox News publish content in full or part from the Associated Press, although the specific stories chosen had not been published in full by either to avoid bias.

We removed the favorability question from Study 1 (as the 3-point scale did not yield significant results), instead asking the reader more directly about media bias by ranking the fairness of the story on a 5-point Likert scale. The trustworthiness question from Study 1 was kept, also on the same 5-point Likert scale.


\subsection{Dataset} 
Eight stories were chosen for this study: two (high and low reading level) per candidate. All eight stories were written by reporters from the Associated Press (although they may have been republished elsewhere).

Reading level cutoffs were made by taking the bottom and top 25\% percentile of Flesch-Kincaid scores for each candidate. From stories written by the Associated Press that made the cutoff, we formed pairs of high and low reading level stories from each topic. The topic with the highest distance between reading level in the pair was chosen for each candidate.

% put histograms of reading level with cutoff lines

 
 
 
\subsection{Survey}

% just pics etc.
\subsection{Quality Control}

As in the first study, users were filtered by minimum time taken to complete the task. Again, only Level 3 workers were chosen from Crowdflower, and users from Study 1 were forbidden to complete tasks in Study 2. 

Because Study 2 presented a longer task of reading 8 versus 5 news stories, we set a longer minimum time of 6 minutes to complete the task. A payment of \$0.80 per survey was given based off guidelines by MIT \cite{COUHES-turk}.

The average response time for the task was 09:20 min.

\section{Analysis}


%Why did you choose trust and fairness?

 
% How did you control for quality?

  
% What kind of people signed up for your study?

% How did you recruit them? What was their incentive?

% What kind of effects were you looking for?
 
% What kind of effects did you find?

\section{Conclusions}

How do your trustworthiness findings line up with the findings from Pew surveys and prior work? What hypotheses did you verify from prior work?

\section{Limitations}

Just 8 stories I know
Yes the diff candidates had diff topics i know
we could have included all candidates
